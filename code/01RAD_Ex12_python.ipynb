{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrystofKlazek/RAD/blob/main/code/01RAD_Ex12_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXrQyd0oWEmt"
      },
      "source": [
        "# Kaggle house data set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fv2Z4i1FyD"
      },
      "source": [
        "\n",
        "## Downloading the Kaggle house rent dataset\n",
        "\n",
        "The dataset we will use comes from Kaggle:\n",
        "\n",
        "- *House Rent Prediction Dataset*  \n",
        "  https://www.kaggle.com/datasets/iamsouravbanerjee/house-rent-prediction-dataset/data\n",
        "\n",
        "To download directly from Kaggle inside this notebook you need a Kaggle\n",
        "API token (see *Account ? API ? Create New Token* on Kaggle). The cell\n",
        "below assumes you have configured your `KAGGLE_USERNAME` and\n",
        "`KAGGLE_KEY` environment variables or placed `kaggle.json` in the\n",
        "standard location.\n",
        "\n",
        "Exampe of Auto NB - let's beat it\n",
        "\n",
        "https://www.kaggle.com/code/sahityasetu/boosting-algorithms-for-machine-learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6-B0G0G1FyE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Download the Kaggle house rent dataset using kagglehub (no API key needed for public data)\n",
        "try:\n",
        "    import kagglehub  # lightweight helper for Kaggle datasets\n",
        "except ImportError:  # pragma: no cover\n",
        "    %pip install -q kagglehub\n",
        "    import kagglehub\n",
        "\n",
        "# Download latest version of the dataset; this returns a local directory path\n",
        "path = kagglehub.dataset_download(\"iamsouravbanerjee/house-rent-prediction-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0rH_bJP1FyI"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as smf\n",
        "from patsy import dmatrices\n",
        "\n",
        "\n",
        "# `path` is a directory returned by kagglehub; locate the CSV inside it\n",
        "dataset_dir = Path(path)\n",
        "candidates = list(dataset_dir.rglob(\"House_Rent_Dataset.csv\"))\n",
        "if not candidates:\n",
        "    raise FileNotFoundError(f\"House_Rent_Dataset.csv not found under {dataset_dir}\")\n",
        "\n",
        "csv_path = candidates[0]\n",
        "print(\"Loading data from:\", csv_path)\n",
        "house = pd.read_csv(csv_path)\n",
        "print(\"Shape:\", house.shape)\n",
        "house.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YInontvb1FyJ"
      },
      "source": [
        "\n",
        "## Questions for a linear regression analysis of house rent\n",
        "\n",
        "When building a linear regression model for rent, it is useful to think\n",
        "in terms of a workflow:\n",
        "\n",
        "1. **Understand the data**\n",
        "   - What is the response variable (e.g. `Rent`)?  \n",
        "     What are the main predictor types (numeric, categorical, locations,\n",
        "     amenities)?\n",
        "   - Are there obvious data quality issues (missing values, impossible\n",
        "     values, outliers)?\n",
        "\n",
        "2. **Preprocessing and feature engineering**\n",
        "   - How should categorical variables (e.g. city, furnishing status,\n",
        "     point of contact) be encoded for a linear model (one?hot encoding,\n",
        "     target encoding, etc.)?\n",
        "   - Which numeric variables might benefit from scaling (standardization\n",
        "     or robust scaling), and why can this matter for regularized\n",
        "     regression?\n",
        "   - Are there interactions that are conceptually meaningful\n",
        "     (e.g. `BHK , Size`, `City , DistanceFromMainArea`)?\n",
        "   - Can we create more interpretable features (e.g. rent per square\n",
        "     foot, distance to city centre bins)?\n",
        "\n",
        "3. **Transformations of response and regressors**\n",
        "   - Is the distribution of `Rent` highly skewed or heavy tailed? Would a\n",
        "     log transformation (modeling $\\log(\\text{Rent})$) stabilize\n",
        "     variance and make residuals closer to normal?\n",
        "   - Do some predictors show non linear relationships with rent? Would\n",
        "     polynomial terms, splines, or monotone transforms (log, square\n",
        "     root) be appropriate?\n",
        "   - Are there predictors that should be centered or standardized before\n",
        "     creating interaction or polynomial terms?\n",
        "\n",
        "4. **Model specification and selection**\n",
        "   - Start with a simple baseline: which variables should be included in\n",
        "     a first OLS model, and how do residual plots look?\n",
        "   - How to compare alternative specifications\n",
        "     (different sets of features, transformed vs untransformed variables)\n",
        "     using cross validation or a validation set?\n",
        "   - When is it useful to move from plain OLS to regularized models such\n",
        "     as ridge or lasso (e.g. many correlated predictors, high variance)?\n",
        "\n",
        "5. **Model evaluation and diagnostics**\n",
        "   - How to check linear model assumptions: residual vs fitted plots,\n",
        "     QQ plots, heteroscedasticity, influential observations?\n",
        "   - Which error metrics are most relevant here\n",
        "     (RMSE, MAE, MAPE)?  How do training and test errors compare\n",
        "     (overfitting vs underfitting)?\n",
        "   - Are there systematic groups of houses (by city, BHK, furnishing)\n",
        "     for which the model performs much worse, suggesting missing\n",
        "     structure or interactions?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbxRhe1J1FyK"
      },
      "source": [
        "\n",
        "### More detailed questions to explore\n",
        "\n",
        "- **Preprocessing**\n",
        "  - How should missing values be handled for each variable (impute,\n",
        "    drop, or create explicit missing indicators)?\n",
        "  - Do we need to cap or Winsorize extreme values of `Rent` or `Size`\n",
        "    before fitting a linear model?\n",
        "  - Are there rare categories (e.g. cities or furnishing statuses with\n",
        "    very few observations) that should be grouped together?\n",
        "\n",
        "- **Transformations and linearity**\n",
        "  - Plot `Rent` (or $\\log(\\text{Rent})$) against key predictors:\n",
        "    `Size`, `BHK`, `Bathroom`, `City`, etc.  Do the relationships look\n",
        "    approximately linear after transformation?\n",
        "  - Would modeling $\\log(\\text{Rent})$ make residuals more symmetric and\n",
        "    reduce heteroscedasticity?\n",
        "\n",
        "- **Multicollinearity and regularization**\n",
        "  - Are some predictors strongly correlated (e.g. `Size` and `BHK`)?  How\n",
        "    do VIFs and condition numbers look for the chosen design matrix?\n",
        "  - How do ridge and lasso behave in this dataset in terms of coefficient\n",
        "    shrinkage and variable selection?\n",
        "  - Which predictors consistently get selected by lasso across\n",
        "    cross?validation folds?\n",
        "\n",
        "- **Model selection and validation**\n",
        "  - How does test error change when we:\n",
        "    1. Add more predictors,\n",
        "    2. Add interaction terms,\n",
        "    3. Add polynomial terms,\n",
        "    4. Switch from OLS to ridge/lasso?\n",
        "  - How to choose the final model: by minimum cross?validated RMSE,\n",
        "    parsimony (fewest predictors), or domain interpretability?\n",
        "\n",
        "Use these questions as a checklist to design your own modeling pipeline\n",
        "for the house rent dataset using linear regression and its regularized\n",
        "variants.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARyiIgPpV7cC"
      },
      "outputs": [],
      "source": [
        "df = house.copy()\n",
        "\n",
        "df.shape\n",
        "df.isna().sum()\n",
        "df.duplicated().sum()\n",
        "df.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All shapes and Nans are fine"
      ],
      "metadata": {
        "id": "TLscasIh7aER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe(percentiles=[.01,.05,.1,.25,.5,.75,.9,.95,.99]))\n",
        "print(df[\"Rent\"].max(), df[\"Size\"].min(), df[\"Size\"].max())\n",
        "\n",
        "df[\"log_rent\"] = np.log(df[\"Rent\"])\n"
      ],
      "metadata": {
        "id": "dLJBO9ZD4-fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['Floor', 'Area Type', 'Area Locality', 'City', 'Furnishing Status', 'Tenant Preferred']:\n",
        "    print(f\"Unique values for '{col}':\")\n",
        "    print(df[col].unique())\n",
        "    print(\"\\n\")\n",
        "    print(f\"Column '{col}': {df[col].nunique()} unique values\")"
      ],
      "metadata": {
        "id": "LB3hAGV36pv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logrent seems reasonable"
      ],
      "metadata": {
        "id": "ji_96UMcABlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See how many values there are to create either one-hot encoding ( Categories - C in the statmodels) or to merge them and then treat them as Categories"
      ],
      "metadata": {
        "id": "xM95C5gK7ou9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2902217"
      },
      "source": [
        "import re\n",
        "\n",
        "def parse_floor(floor_str):\n",
        "    floor_str = str(floor_str).lower().strip()\n",
        "    current_floor = None\n",
        "    total_floors = None\n",
        "\n",
        "    # Handle 'X out of Y' format\n",
        "    match_out_of = re.match(r'(.+) out of (\\d+)', floor_str)\n",
        "    if match_out_of:\n",
        "        current_part = match_out_of.group(1).strip()\n",
        "        total_floors = int(match_out_of.group(2))\n",
        "    else:\n",
        "        current_part = floor_str\n",
        "\n",
        "    if current_part == 'ground':\n",
        "        current_floor = 0\n",
        "    elif current_part == 'upper basement':\n",
        "        current_floor = -1\n",
        "    elif current_part == 'lower basement':\n",
        "        current_floor = -2\n",
        "    else:\n",
        "        try:\n",
        "            current_floor = int(current_part)\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # If total_floors wasn't extracted from 'out of Y' and current_floor is known and non-negative,\n",
        "    # assume total_floors is the same as current_floor (e.g., \"3\" means 3 out of 3).\n",
        "    if total_floors is None and current_floor is not None and current_floor >= 0:\n",
        "        total_floors = current_floor\n",
        "\n",
        "    if current_floor is None or total_floors is None:\n",
        "        raise ValueError(f\"Could not parse floor string: '{floor_str}'\")\n",
        "\n",
        "    return current_floor, total_floors\n",
        "\n",
        "df[['current_floor', 'total_floors']] = df['Floor'].apply(lambda x: pd.Series(parse_floor(x)))\n",
        "\n",
        "print(\"Original 'Floor' column unique values:\")\n",
        "print(df['Floor'].unique())\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"New 'current_floor' unique values:\")\n",
        "print(df['current_floor'].unique())\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"New 'total_floors' unique values:\")\n",
        "print(df['total_floors'].unique())\n",
        "print(\"\\n\")\n",
        "\n",
        "display(df[['Floor', 'current_floor', 'total_floors']].head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical values from floors"
      ],
      "metadata": {
        "id": "BQJ7LhWQ7wcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"Area Type\"] != \"Built Area\"].copy()\n",
        "\n",
        "min_n = 20\n",
        "counts = df[\"Area Locality\"].value_counts()\n",
        "keep = counts[counts >= min_n].index\n",
        "\n",
        "df[\"AreaLocality_grp\"] = np.where(df[\"Area Locality\"].isin(keep),\n",
        "                                  df[\"Area Locality\"],\n",
        "                                  \"Other\")\n",
        "\n",
        "print(f\"Unique values for AreaLocality_grp:\")\n",
        "print(df[\"AreaLocality_grp\"].unique())\n",
        "print(\"\\n\")\n",
        "print(f\"Column 'Arealocality_grp': {df[\"AreaLocality_grp\"].nunique()} unique values\")\n",
        "\n"
      ],
      "metadata": {
        "id": "e7BnPPLD-lqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating \"popular localities that can giv esome info\" and \"other\""
      ],
      "metadata": {
        "id": "zsS-_Du471Qr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztaVvcBEWNH8"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df[\"Rent\"], bins=60)\n",
        "plt.yscale(\"log\")\n",
        "plt.title(\"Rent (log y-scale)\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(df[\"log_rent\"], bins=60)\n",
        "plt.title(\"log(Rent)\")\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data=df, x=\"Size\", y=\"log_rent\", hue=\"City\", alpha=0.4, linewidth=0)\n",
        "plt.title(\"Rent vs Size (log y-scale)\")\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(data=df, x=\"City\", y=\"log_rent\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.title(\"log_rent by City\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formula_loc_grp = \"\"\"\n",
        "log_rent ~ Size + BHK + Bathroom\n",
        "+ C(City) + C(Q(\"Furnishing Status\")) + C(Q(\"Tenant Preferred\")) + C(Q(\"Area Type\"))\n",
        "+ C(AreaLocality_grp)\n",
        "\"\"\"\n",
        "m_loc_grp = smf.ols(formula_loc_grp, data=df).fit(cov_type=\"HC3\")\n",
        "print(m_loc_grp.summary())\n",
        "\n",
        "formula_area_interact = \"\"\"\n",
        "log_rent ~ Size:C(Q(\"City\")) + BHK + Bathroom\n",
        "+ C(City) + C(Q(\"Furnishing Status\")) + C(Q(\"Tenant Preferred\"))\n",
        "+ C(AreaLocality_grp)\n",
        "\"\"\"\n",
        "m_area = smf.ols(formula_area_interact, data=df).fit(cov_type=\"HC3\")\n",
        "print(m_area.summary())\n",
        "\n",
        "formula_area_interact_floors = \"\"\"\n",
        "log_rent ~ Size:C(Q(\"City\")) + BHK + Bathroom current_floor*total_floors\n",
        "+ C(City) + C(Q(\"Furnishing Status\")) + C(Q(\"Tenant Preferred\"))\n",
        "+ C(AreaLocality_grp)\n",
        "\"\"\"\n",
        "m_floors = smf.ols(formula_area_interact_floors, data=df).fit(cov_type=\"HC3\")\n",
        "print(m_floors.summary())\n",
        "\n",
        "formula_area_interact_floors2 = \"\"\"\n",
        "log_rent ~ Size:C(Q(\"City\")) + BHK + Bathroom + current_floor+total_floors\n",
        "+ C(City) + C(Q(\"Furnishing Status\")) + C(Q(\"Tenant Preferred\"))\n",
        "+ C(AreaLocality_grp)\n",
        "\"\"\"\n",
        "m_floors2 = smf.ols(formula_area_interact_floors2, data=df).fit(cov_type=\"HC3\")\n",
        "print(m_floors2.summary())"
      ],
      "metadata": {
        "id": "FaQJYl6A_M_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model floors seems the best to me, because then there is not such a problem with the colinearity with total floors and  current floor and yet seems to have nicce power - not the final model, just testing for now"
      ],
      "metadata": {
        "id": "DdvfiE1_7-yD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzp64AaEWNK-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def loocv_rmse_mae_ols(formula, data, y_col=\"log_rent\", cov_type=None):\n",
        "    fit = smf.ols(formula, data=data).fit() if cov_type is None else smf.ols(formula, data=data).fit(cov_type=cov_type)\n",
        "\n",
        "    infl = OLSInfluence(fit)\n",
        "    h = infl.hat_matrix_diag\n",
        "    e = fit.resid.values\n",
        "    press = e / (1.0 - h)\n",
        "\n",
        "    rmse = np.sqrt(np.mean(press**2))\n",
        "    mae  = np.mean(np.abs(press))\n",
        "    return rmse, mae, fit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import OLSInfluence\n",
        "\n",
        "formulas = {\n",
        "    \"Model1\": formula_loc_grp,\n",
        "    \"Model2\": formula_area_interact,\n",
        "    \"Model3\": formula_area_interact_floors,\n",
        "    \"Model4\": formula_area_interact_floors2,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, f in formulas.items():\n",
        "    rmse, mae, _ = loocv_rmse_mae_ols(f, df, cov_type=\"HC3\")\n",
        "    results[name] = {\"PRESS_RMSE_log\": rmse, \"PRESS_MAE_log\": mae}\n",
        "\n",
        "pd.DataFrame(results).T.sort_values(\"PRESS_RMSE_log\")"
      ],
      "metadata": {
        "id": "sDteBOmot0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3 - the one wit hthe floor interaction - looks good here also - I start with this maximal model and then move down"
      ],
      "metadata": {
        "id": "J7R7blWX_wL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formula_best = formula_area_interact_floors\n",
        "m_best = m_floors"
      ],
      "metadata": {
        "id": "8_kb4PXkufHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diag = df.copy()\n",
        "df_diag[\"y\"] = df_diag[\"log_rent\"]\n",
        "df_diag[\"yhat\"] = m_best.fittedvalues\n",
        "df_diag[\"resid\"] = m_best.resid\n",
        "\n",
        "influence = m_best.get_influence()\n",
        "\n",
        "df_diag[\"resid_studentized\"] = influence.resid_studentized\n",
        "df_diag[\"hat\"] = influence.hat_matrix_diag\n",
        "df_diag[\"cooks_d\"] = influence.cooks_distance[0]\n",
        "\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "sns.scatterplot(data=df_diag, x=\"yhat\", y=\"resid\", alpha=0.35, linewidth=0)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.title(\"Residuals vs Fitted (log space)\")\n",
        "plt.show()\n",
        "\n",
        "qqplot(df_diag[\"resid_studentized\"], line=\"45\")\n",
        "plt.title(\"QQ plot of residuals\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(df_diag[\"resid\"], bins=60)\n",
        "plt.title(\"Residual distribution (log space)\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(df_diag[\"resid_studentized\"], bins=60)\n",
        "plt.title(\"Histogram of Studentized Residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L77SSQH_v2Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wbe-N6UVwcfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "sns.scatterplot(data=df_diag, x=\"hat\", y=np.abs(df_diag[\"resid_studentized\"]),\n",
        "                size=\"cooks_d\", sizes=(20, 400), alpha=0.6, linewidth=0, hue='cooks_d', palette='viridis')\n",
        "plt.axhline(2, linestyle=\"--\", color='grey', label=\"|Studentized Residual| = 2\")\n",
        "plt.axhline(3, linestyle=\"--\", color='red', label=\"|Studentized Residual| = 3\")\n",
        "plt.title(\"Influence Plot: Leverage vs. Absolute Studentized Residuals (size ~ Cook's D)\")\n",
        "plt.xlabel(\"Leverage (Hat value)\")\n",
        "plt.ylabel(\"|Studentized Residuals|\")\n",
        "plt.legend(title=\"Legend\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.scatterplot(data=df_diag, x=\"hat\", y=np.abs(df_diag[\"resid_studentized\"]),\n",
        "                size=\"cooks_d\", sizes=(20, 400), alpha=0.6, linewidth=0, hue='cooks_d', palette='viridis')\n",
        "plt.axhline(2, linestyle=\"--\", color='grey', label=\"|Studentized Residual| = 2\")\n",
        "plt.axhline(3, linestyle=\"--\", color='red', label=\"|Studentized Residual| = 3\")\n",
        "plt.title(\"Influence Plot: Leverage vs. Absolute Studentized Residuals (size ~ Cook's D)\")\n",
        "plt.xlabel(\"Leverage (Hat value)\")\n",
        "plt.ylabel(\"|Studentized Residuals|\")\n",
        "plt.xscale('log') # Leverage can be skewed, log scale might help visualization\n",
        "plt.legend(title=\"Legend\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Cth-Kippw73N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "influence = m_best.get_influence()\n",
        "\n",
        "df_diag[\"hat\"] = influence.hat_matrix_diag\n",
        "df_diag[\"stud\"] = influence.resid_studentized_external\n",
        "df_diag[\"cooks_d\"] = influence.cooks_distance[0]\n",
        "\n",
        "# Top influential\n",
        "top_cook = df_diag.sort_values(\"cooks_d\", ascending=False).head(15)\n",
        "top_out  = df_diag.reindex(df_diag[\"stud\"].abs().sort_values(ascending=False).index).head(15)\n",
        "\n",
        "cols = [\"Rent\",\"log_rent\",\"yhat\",\"resid\",\"stud\",\"hat\",\"cooks_d\"]\n",
        "\n",
        "top_cook[cols], top_out[cols]"
      ],
      "metadata": {
        "id": "TZfbQxtW0ga9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_idx = [1837, 3656, 4076]\n",
        "\n",
        "tmp = df_diag.loc[top_idx, [\"Rent\",\"log_rent\",\"yhat\",\"resid\",\"stud\",\"hat\",\"cooks_d\"]].copy()\n",
        "tmp[\"ratio_actual_to_pred\"] = np.exp(tmp[\"resid\"])          # ~ actual/predicted\n",
        "tmp[\"abs_pct_error_like\"] = np.abs(tmp[\"ratio_actual_to_pred\"] - 1)\n",
        "\n",
        "tmp.sort_values(\"cooks_d\", ascending=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wOLIMPZr07eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[top_idx]"
      ],
      "metadata": {
        "id": "I1Ojf5Bh2PAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfbetas = pd.DataFrame(influence.dfbetas, columns=m_best.params.index, index=df.index)\n",
        "\n",
        "# which observations most affect coefficients (max abs dfbeta across params)\n",
        "df_diag[\"max_abs_dfbeta\"] = dfbetas.abs().max(axis=1)\n",
        "\n",
        "df_diag.sort_values(\"max_abs_dfbeta\", ascending=False).head(15)[\n",
        "    [\"Rent\",\"Size\",\"BHK\",\"Bathroom\",\"stud\",\"hat\",\"cooks_d\",\"max_abs_dfbeta\"]\n",
        "]\n"
      ],
      "metadata": {
        "id": "MJh9wJFu2203"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suspects = [4185, 2656, 4696, 3019, 4457]\n",
        "df.loc[suspects]\n",
        "\n",
        "df[\"Area Type\"].value_counts(dropna=False)\n"
      ],
      "metadata": {
        "id": "KGMlqCAt71tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nejpravděpoodobněji se jedná o chyba týden místo měsíc / rok místo měsíc - proto upravit\n",
        "df_old = df.copy()\n",
        "df = df_old.copy()\n",
        "\n",
        "df.loc[1837, 'Rent'] = df.loc[1837, 'Rent']/np.float64(12)\n",
        "df.loc[3656, 'Rent'] = df.loc[3656, 'Rent']/np.float64(12)\n",
        "df.loc[4076, 'Rent'] = df.loc[3656, 'Rent']*np.float64(4.3)\n",
        "bad_clear = [2656, 4185]\n",
        "\n",
        "\n",
        "df = df[df[\"Area Type\"] != \"Built Area\"].copy()\n",
        "\n",
        "df = df.drop(index=bad_clear, errors=\"ignore\")\n",
        "df[\"log_rent\"] = np.log(df[\"Rent\"])\n",
        "\n",
        "#A tyhle mi přišly jako chybné - proto vyhodit\n",
        "m_drop = smf.ols(m_best.model.formula, data=df).fit(cov_type=\"HC3\")\n",
        "print(m_drop.summary())\n",
        "\n",
        "m_best = m_drop"
      ],
      "metadata": {
        "id": "aJNwaTMf4yjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infl = m_best.get_influence()\n",
        "df_diag = df.copy()\n",
        "df_diag[\"y\"] = df_diag[\"log_rent\"]\n",
        "df_diag[\"yhat\"] = m_best.fittedvalues\n",
        "df_diag[\"resid\"] = m_best.resid\n",
        "\n",
        "df_diag[\"hat\"] = infl.hat_matrix_diag\n",
        "df_diag[\"stud\"] = infl.resid_studentized_external\n",
        "df_diag[\"cooks_d\"] = infl.cooks_distance[0]\n",
        "\n",
        "# Top influential\n",
        "top_cook = df_diag.sort_values(\"cooks_d\", ascending=False).head(15)\n",
        "top_out  = df_diag.reindex(df_diag[\"stud\"].abs().sort_values(ascending=False).index).head(15)\n",
        "\n",
        "cols = [\"Rent\",\"log_rent\",\"yhat\",\"resid\",\"stud\",\"hat\",\"cooks_d\"]\n",
        "\n",
        "top_cook[cols], top_out[cols]\n"
      ],
      "metadata": {
        "id": "5oamttZXKfrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import patsy\n",
        "\n",
        "y, X = patsy.dmatrices(formula_area_interact_floors, data=df, return_type=\"dataframe\")\n",
        "X.shape, y.shape\n",
        "\n",
        "svals = np.linalg.svd(X.values, compute_uv=False)\n",
        "kappa = svals[0] / svals[-1]\n",
        "kappa\n"
      ],
      "metadata": {
        "id": "Uq90YPva9bJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif = pd.DataFrame({\n",
        "    \"term\": X.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "}).sort_values(\"VIF\", ascending=False)\n",
        "\n",
        "vif.head(30)\n"
      ],
      "metadata": {
        "id": "ru6Cwk8NAJMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import patsy\n",
        "\n",
        "y, X = patsy.dmatrices(formula_best, data=df, return_type=\"dataframe\")\n",
        "\n",
        "# drop intercept for correlation\n",
        "X2 = X.drop(columns=[\"Intercept\"], errors=\"ignore\")\n",
        "\n",
        "top_cols = X2.var().sort_values(ascending=False).head(30).index\n",
        "corrX = X2[top_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corrX, center=0, square=True)\n",
        "plt.title(\"Correlation matrix (design matrix subset)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "86kwqRLn_cPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "terms = [\"Size\", \"current_floor\", \"total_floors\", \"BHK\", \"Bathroom\",]\n",
        "\n",
        "for t in terms:\n",
        "    cols = [i for i, name in enumerate(m_best.model.exog_names) if name == t]\n",
        "    if not cols:\n",
        "        continue\n",
        "    sm.graphics.plot_ccpr(m_best, cols[0])\n",
        "    plt.title(f\"CCPR (partial residual) for {t}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Dwgns5TgFgGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "exog_names = list(m_best.model.exog_names)\n",
        "\n",
        "def plot_ccpr_by_name(model, name):\n",
        "    exog = list(model.model.exog_names)\n",
        "    if name not in exog:\n",
        "        print(f\"Not found: {name}\")\n",
        "        return\n",
        "    idx = exog.index(name)\n",
        "    sm.graphics.plot_ccpr(model, idx)\n",
        "    plt.title(f\"CCPR (partial residual) for {name}\")\n",
        "    plt.show()\n",
        "\n",
        "# --- 1) floor interaction (either order) ---\n",
        "floor_terms = [n for n in exog_names if (\"current_floor\" in n and \"total_floors\" in n and \":\" in n)]\n",
        "print(\"Floor interaction terms found:\", floor_terms)\n",
        "for t in floor_terms:\n",
        "    plot_ccpr_by_name(m_best, t)\n",
        "\n",
        "# --- 2) Size × Area Type interaction terms (use your actual naming) ---\n",
        "area_terms = [n for n in exog_names if n.startswith('Size:C(Q(\"Area Type\"))[')]\n",
        "print(\"Area Type interaction terms found:\", area_terms)\n",
        "for t in area_terms:\n",
        "    plot_ccpr_by_name(m_best, t)\n"
      ],
      "metadata": {
        "id": "Zwexk3y7Sd7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These look Roughly linear but not 100%"
      ],
      "metadata": {
        "id": "tTNxZxNwAbbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df2 = df.copy()\n",
        "df2[\"log_Size\"] = np.log(df2[\"Size\"])\n",
        "df2[\"sqrt_Size\"] = np.sqrt(df2[\"Size\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "mImp2UUIIg-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def loocv_press(formula, data):\n",
        "    m = smf.ols(formula, data=data).fit()\n",
        "    infl = m.get_influence()\n",
        "    h = infl.hat_matrix_diag\n",
        "    e = m.resid.values\n",
        "    loo_resid = e / (1 - h)\n",
        "    rmse = float(np.sqrt(np.mean(loo_resid**2)))\n",
        "    mae = float(np.mean(np.abs(loo_resid)))\n",
        "    return rmse, mae, m\n"
      ],
      "metadata": {
        "id": "6nm56hH7Ikq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from patsy import bs\n",
        "\n",
        "base_formula = m_best.model.formula\n",
        "\n",
        "formulas = {\n",
        "    \"baseline\": base_formula,\n",
        "\n",
        "    \"log(Size)\": base_formula.replace(\"Size\", \"log_Size\"),\n",
        "    \"sqrt(Size)\": base_formula.replace(\"Size\", \"sqrt_Size\"),\n",
        "\n",
        "    \"bs(Size,df=5)\": base_formula.replace(\"Size\", \"bs(Size, df=5, degree=3)\")\n",
        "    }\n",
        "\n",
        "\n",
        "rows = []\n",
        "models = {}\n",
        "for name, f in formulas.items():\n",
        "    rmse, mae, m = loocv_press(f, df2)\n",
        "    rows.append((name, rmse, mae, m.aic, m.bic))\n",
        "    models[name] = m\n",
        "\n",
        "res = pd.DataFrame(rows, columns=[\"model\",\"LOO_RMSE_log\",\"LOO_MAE_log\",\"AIC\",\"BIC\"]).sort_values(\"LOO_RMSE_log\")\n",
        "res\n"
      ],
      "metadata": {
        "id": "wEMB-LKSIm86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diag = df.copy()\n",
        "df_diag[\"y\"] = df_diag[\"log_rent\"]\n",
        "df_diag[\"yhat\"] = m_best.fittedvalues\n",
        "df_diag[\"resid\"] = m_best.resid\n",
        "\n",
        "influence = m_best.get_influence()\n",
        "\n",
        "df_diag[\"resid_studentized\"] = influence.resid_studentized\n",
        "df_diag[\"hat\"] = influence.hat_matrix_diag\n",
        "df_diag[\"cooks_d\"] = influence.cooks_distance[0]\n",
        "\n",
        "sns.scatterplot(data=df_diag, x=\"yhat\", y=\"resid\", alpha=0.35, linewidth=0)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.title(\"Residuals vs Fitted (log space)\")\n",
        "plt.show()\n",
        "\n",
        "qqplot(df_diag[\"resid_studentized\"], line=\"45\")\n",
        "plt.title(\"QQ plot of residuals\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(df_diag[\"resid\"], bins=60)\n",
        "plt.title(\"Residual distribution (log space)\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(df_diag[\"resid_studentized\"], bins=60)\n",
        "plt.title(\"Histogram of Studentized Residuals\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GxgZCLPkKBce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few too heavy on the right tail - makes sense, probably some extra luxurious location not accounted for"
      ],
      "metadata": {
        "id": "Ep9K408RIjU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x=m_best.fittedvalues, y=m_best.resid, alpha=0.35, linewidth=0)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Predicted')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yQhylu0IRi2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question answers:\n",
        "\n",
        "Adding more predictors\n",
        "\n",
        "Training error: always goes down (or stays the same).\n",
        "\n",
        "Test/CV error: often goes down at first, then flattens, and can go back up (overfitting).\n",
        "\n",
        "Adding interaction terms\n",
        "\n",
        "Helps only if the interaction is real (e.g., Size effect differs by City).\n",
        "\n",
        "Otherwise it increases variance a lot → test error often worsens unless regularized."
      ],
      "metadata": {
        "id": "OGTNWmDkRmrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLEANING HAS BEEN DONE TO MAKE THE MAXIMAL MODEL USABLE\n",
        "\n",
        "NOW ONTO THE OTHER ONES - Train split and all"
      ],
      "metadata": {
        "id": "RDoe9iH3JS3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The split is done so that cities are balanced"
      ],
      "metadata": {
        "id": "zA7eDcIFFu_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_use = df.copy()\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df_use,\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        "    stratify=df_use[\"City\"]\n",
        ")\n",
        "\n",
        "\n",
        "train_df[\"floor_frac\"] = train_df[\"current_floor\"] / train_df[\"total_floors\"].replace(0, np.nan)\n",
        "val_df[\"floor_frac\"]   = val_df[\"current_floor\"]   / val_df[\"total_floors\"].replace(0, np.nan)\n",
        "\n",
        "train_df[\"floor_frac\"] = train_df[\"floor_frac\"].fillna(0)\n",
        "val_df[\"floor_frac\"]   = val_df[\"floor_frac\"].fillna(0)\n",
        "\n",
        "\n",
        "train_df.shape, val_df.shape"
      ],
      "metadata": {
        "id": "h22M2w2HJSNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for col in train_df.columns:\n",
        "    print(f\"\\n=== {col} ===\")\n",
        "\n",
        "    # numeric columns: overlay histograms (density)\n",
        "    if pd.api.types.is_numeric_dtype(train_df[col]):\n",
        "        plt.figure()\n",
        "        sns.histplot(train_df[col], stat=\"density\", bins=30, alpha=0.35, label=\"train\")\n",
        "        sns.histplot(val_df[col],   stat=\"density\", bins=30, alpha=0.35, label=\"val\")\n",
        "        plt.title(f\"{col} (numeric)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    # everything else: show normalized value counts side-by-side\n",
        "    else:\n",
        "        vc_train = train_df[col].value_counts(normalize=True)\n",
        "        vc_val   = val_df[col].value_counts(normalize=True)\n",
        "\n",
        "        dist = pd.concat([vc_train.rename(\"train\"), vc_val.rename(\"val\")], axis=1).fillna(0)\n",
        "        print(dist.sort_values(\"train\", ascending=False))\n",
        "\n",
        "        # plot as bar chart\n",
        "        dist.plot(kind=\"bar\", figsize=(10, 4))\n",
        "        plt.title(f\"{col} (categorical) – normalized frequencies\")\n",
        "        plt.ylabel(\"proportion\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "lRURbzoYGKsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe the floors could introduce a bit of a problem"
      ],
      "metadata": {
        "id": "4vwXaO0FJlCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_model(formula, train_df, val_df):\n",
        "    m = smf.ols(formula, data=train_df).fit(cov_type=\"HC3\")\n",
        "\n",
        "    pred_log = m.predict(val_df)\n",
        "    y_log = val_df[\"log_rent\"].values\n",
        "    err_log = y_log - pred_log.values\n",
        "    rmse_log = float(np.sqrt(np.mean(err_log**2)))\n",
        "    mae_log  = float(np.mean(np.abs(err_log)))\n",
        "\n",
        "    pred_rent = np.exp(pred_log)\n",
        "    y_rent = val_df[\"Rent\"].values\n",
        "    err_rent = y_rent - pred_rent.values\n",
        "    rmse_rent = float(np.sqrt(np.mean(err_rent**2)))\n",
        "    mae_rent  = float(np.mean(np.abs(err_rent)))\n",
        "\n",
        "    return m, rmse_log, mae_log, rmse_rent, mae_rent\n",
        "\n",
        "baseline_formula = \"\"\"\n",
        "log_rent ~ Size * C(Q(\"Area Type\")) + BHK + Bathroom + current_floor*total_floors\n",
        "+ C(City) + C(Q(\"Furnishing Status\")) + C(Q(\"Tenant Preferred\"))\n",
        "+ C(AreaLocality_grp) + C(Q(\"Area Type\"))\n",
        "\"\"\"\n",
        "\n",
        "m0, rmse_log, mae_log, rmse_rent, mae_rent = score_model(baseline_formula, train_df, val_df)\n",
        "\n",
        "results0 = pd.DataFrame([[\n",
        "    \"baseline\", rmse_log, mae_log, rmse_rent, mae_rent, m0.aic, m0.bic\n",
        "]], columns=[\"model\",\"RMSE_log\",\"MAE_log\",\"RMSE_Rent\",\"MAE_Rent\",\"AIC_train\",\"BIC_train\"])\n",
        "\n",
        "results0\n"
      ],
      "metadata": {
        "id": "rBe6zGmuKK5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_bic(formula, data):\n",
        "    m = smf.ols(formula, data=data).fit()\n",
        "    return m, float(m.bic), float(m.aic)\n",
        "\n",
        "def build_formula(fixed_terms, optional_terms):\n",
        "    rhs = fixed_terms + optional_terms\n",
        "    rhs = [t.strip() for t in rhs if t.strip()]\n",
        "    return \"log_rent ~ \" + \" + \".join(rhs)\n",
        "\n",
        "def stepwise_bic(train_df, fixed_terms, start_optional, optional_pool, max_steps=50, verbose=True):\n",
        "    current_opt = list(start_optional)\n",
        "    current_formula = build_formula(fixed_terms, current_opt)\n",
        "    current_model, current_bic, current_aic = fit_bic(current_formula, train_df)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Start BIC: {current_bic:.3f}\")\n",
        "        print(current_formula)\n",
        "\n",
        "    for step in range(1, max_steps + 1):\n",
        "        candidates = []\n",
        "        curset = set(current_opt)\n",
        "\n",
        "        # add-one\n",
        "        for t in optional_pool:\n",
        "            if t in curset:\n",
        "                continue\n",
        "            new_opt = list(curset | {t})\n",
        "            f = build_formula(fixed_terms, new_opt)\n",
        "            try:\n",
        "                m, bic, aic = fit_bic(f, train_df)\n",
        "                candidates.append((\"add\", t, new_opt, f, m, bic, aic))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # remove-one (only from current optional set)\n",
        "        for t in list(curset):\n",
        "            newset = set(curset)\n",
        "            newset.remove(t)\n",
        "            new_opt = list(newset)\n",
        "            f = build_formula(fixed_terms, new_opt)\n",
        "            try:\n",
        "                m, bic, aic = fit_bic(f, train_df)\n",
        "                candidates.append((\"remove\", t, new_opt, f, m, bic, aic))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        best = min(candidates, key=lambda x: x[5])\n",
        "        move, term, best_opt, best_formula, best_model, best_bic, best_aic = best\n",
        "\n",
        "        if best_bic + 1e-9 < current_bic:\n",
        "            current_opt = best_opt\n",
        "            current_formula = best_formula\n",
        "            current_model = best_model\n",
        "            current_bic = best_bic\n",
        "            current_aic = best_aic\n",
        "            if verbose:\n",
        "                print(f\"\\nStep {step}: {move} {term}\")\n",
        "                print(f\"  BIC -> {current_bic:.3f} | AIC -> {current_aic:.3f}\")\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"\\nNo further BIC improvement. Stop.\")\n",
        "            break\n",
        "\n",
        "    return current_model, current_formula, current_bic, current_aic\n"
      ],
      "metadata": {
        "id": "elv-Mz9WL_K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_terms = [\"C(City)\"]\n",
        "\n",
        "# Start from the baseline (minus City, which is fixed)\n",
        "start_optional = [\n",
        "    \"Size\", \"BHK\", \"Bathroom\", \"floor_frac\",\n",
        "    \"current_floor\", \"total_floors\", \"current_floor:total_floors\",\n",
        "    'C(Q(\"Furnishing Status\"))',\n",
        "    'C(Q(\"Tenant Preferred\"))',\n",
        "    \"C(AreaLocality_grp)\",\n",
        "    'C(Q(\"Area Type\"))', \"Size:C(AreaLocality_grp)\"\n",
        "]\n",
        "\n",
        "optional_pool = start_optional.copy() + [\"Size:C(City)\"]\n",
        "\n",
        "best_train_model, best_formula, best_bic, best_aic = stepwise_bic(\n",
        "    train_df=train_df,\n",
        "    fixed_terms=fixed_terms,\n",
        "    start_optional=start_optional,\n",
        "    optional_pool=optional_pool,\n",
        "    max_steps=50,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== Best by TRAIN BIC ===\")\n",
        "print(\"BIC:\", best_bic)\n",
        "print(\"AIC:\", best_aic)\n",
        "print(best_formula)"
      ],
      "metadata": {
        "id": "8wbyhBvUMeSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WHAT ABOUT IF WITH FLOOR FRAC and from floor up?\n",
        "\n",
        "fixed_terms = [\"C(City)\"]\n",
        "\n",
        "optional_pool = [\n",
        "    \"Size\", \"BHK\", \"Bathroom\",\n",
        "    \"current_floor\", \"total_floors\", \"current_floor:total_floors\",\n",
        "    \"floor_frac\",\n",
        "    'C(Q(\"Furnishing Status\"))',\n",
        "    'C(Q(\"Tenant Preferred\"))',\n",
        "    \"C(AreaLocality_grp)\",\n",
        "    'C(Q(\"Area Type\"))', \"Size:C(City)\", \"Size:C(AreaLocality_grp)\"\n",
        "]\n",
        "\n",
        "start_optional = [\"Size\"]\n",
        "\n",
        "best_train_model, best_formula, best_bic, best_aic = stepwise_bic(\n",
        "    train_df=train_df,\n",
        "    fixed_terms=fixed_terms,\n",
        "    start_optional=start_optional,\n",
        "    optional_pool=optional_pool,\n",
        "    max_steps=50,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== Best by TRAIN BIC ===\")\n",
        "print(\"BIC:\", best_bic)\n",
        "print(\"AIC:\", best_aic)\n",
        "print(best_formula)\n"
      ],
      "metadata": {
        "id": "IrzkPfYUP54E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE SAME RESULT, SO THIS IS THE DEFINITE PREFFERED MODEL.\n",
        "\n",
        "I focus on \"Interpretability\" and not the best predictive power - that is why I focus on BIC/AIC. If we wanted the highest predictiv epower on this type of data, it could start to get ugly real fast."
      ],
      "metadata": {
        "id": "9TW26WXjRDCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "formula_city_slope = \"\"\"\n",
        "log_rent ~ C(City) + C(Q(\"Tenant Preferred\")) + Bathroom\n",
        "+ C(AreaLocality_grp) + C(Q(\"Furnishing Status\")) + BHK + C(Q(\"Area Type\"))\n",
        "+ Size * C(City) + total_floors\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "f_no_int = \"\"\"\n",
        "log_rent ~ C(City) + C(Q(\"Tenant Preferred\")) + Bathroom\n",
        "+ C(AreaLocality_grp) + C(Q(\"Furnishing Status\")) + BHK + C(Q(\"Area Type\"))\n",
        "+ Size + total_floors\n",
        "\"\"\"\n",
        "\n",
        "f_int = formula_city_slope\n",
        "\n",
        "m_no = smf.ols(f_no_int, data=train_df).fit()\n",
        "m_in = smf.ols(f_int,   data=train_df).fit()\n",
        "\n",
        "_, rmse0, mae0, _, _ = score_model(f_no_int, train_df, val_df)\n",
        "_, rmse1, mae1, _, _ = score_model(f_int,    train_df, val_df)\n",
        "\n",
        "rmse0, rmse1, mae0, mae1\n"
      ],
      "metadata": {
        "id": "DaxezD1vT9TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "params = m_in.params\n",
        "\n",
        "base_city = [c for c in train_df[\"City\"].unique() if f\"C(City)[T.{c}]\" not in params.index][0]\n",
        "base_slope = params[\"Size\"]\n",
        "\n",
        "slopes = []\n",
        "for city in sorted(train_df[\"City\"].unique()):\n",
        "    adj_name = f\"Size:C(City)[T.{city}]\"\n",
        "    slope = base_slope + (params[adj_name] if adj_name in params.index else 0.0)\n",
        "    slopes.append((city, slope))\n",
        "\n",
        "pd.DataFrame(slopes, columns=[\"City\", \"d(log_rent)/d(Size)\"]).sort_values(\"d(log_rent)/d(Size)\", ascending=False)\n"
      ],
      "metadata": {
        "id": "UIHEnMf7T2XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems that the interaction really makes sense."
      ],
      "metadata": {
        "id": "iVha2aHQUxk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to check for overfit:"
      ],
      "metadata": {
        "id": "NYnT-4ocUxuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_and_error(formula, train_df, val_df):\n",
        "    m = smf.ols(formula, data=train_df).fit()\n",
        "\n",
        "    pred_tr = m.predict(train_df)\n",
        "    pred_va = m.predict(val_df)\n",
        "\n",
        "    err_tr = train_df[\"log_rent\"].values - pred_tr.values\n",
        "    err_va = val_df[\"log_rent\"].values   - pred_va.values\n",
        "\n",
        "    out = pd.DataFrame([{\n",
        "        \"RMSE_train\": float(np.sqrt(np.mean(err_tr**2))),\n",
        "        \"RMSE_val\":   float(np.sqrt(np.mean(err_va**2))),\n",
        "        \"MAE_train\":  float(np.mean(np.abs(err_tr))),\n",
        "        \"MAE_val\":    float(np.mean(np.abs(err_va))),\n",
        "        \"RMSE_gap\":   float(np.sqrt(np.mean(err_va**2)) - np.sqrt(np.mean(err_tr**2))),\n",
        "        \"MAE_gap\":    float(np.mean(np.abs(err_va)) - np.mean(np.abs(err_tr))),\n",
        "        \"R2_train\":   float(m.rsquared),\n",
        "        \"n_train\":    int(len(train_df)),\n",
        "        \"n_val\":      int(len(val_df)),\n",
        "    }])\n",
        "    return m, out\n",
        "\n",
        "m, err_table = fit_and_error(formula_city_slope, train_df, val_df)\n",
        "err_table"
      ],
      "metadata": {
        "id": "YK1n26R1U0Px"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}